{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da8dad8",
   "metadata": {},
   "source": [
    "# Creates kerchunks from specified pattern or files on Azure Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install autopep8\n",
    "\n",
    "import fsspec\n",
    "import ujson\n",
    "import xarray as xr\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from kerchunk.hdf import SingleHdf5ToZarr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adlfs\n",
    "\n",
    "print(adlfs.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to see the available file systems\n",
    "#fsspec.available_protocols()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfb63f",
   "metadata": {},
   "source": [
    "## Needs to be improved... i.e. obtained from other credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be improved\n",
    "account_dict = dict(account_name = \"<get this from the azure portal: storage account name>\",\n",
    "               account_key=\"<get this from the azure portal for this account name: key>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae81828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate fsspec filesystems for reading and writing\n",
    "fs_read = fsspec.filesystem(\"abfs\", **account_dict)\n",
    "\n",
    "#fs_write = fsspec.filesystem(\"\")\n",
    "fs_write = fsspec.filesystem(\"file\")\n",
    "\n",
    "#!az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve list of available files. Can take a long time\n",
    "#files_paths = fs_read.glob(\"abfs://bay-delta-schism2-v58/eli/simulations/hindcast_clinic2/outputs/schout_0000_1*.nc\")\n",
    "# Here we prepend the prefix 'abfs://', which points to Azure Blobs.\n",
    "#file_pattern = sorted([\"abfs://\" + f for f in files_paths])# faster if you already know the patterns expected.\n",
    "file_pattern = [f'abfs://bay-delta-schism2-v58/eli/simulations/hindcast_clinic2/outputs/schout_0000_{i}.nc' for i in range(1,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b390834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to hang for later operations if I introspect here ...\n",
    "#ds = xr.open_dataset(fs_read.open(file_pattern[0]))\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcccd08",
   "metadata": {},
   "source": [
    "## Generate the zarr jsons for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_dict = dict(mode=\"rb\", default_fill_cache=False, default_cache_type=\"first\")\n",
    "output_dir = \"./hindcast2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df42334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kerchunk's `SingleHdf5ToZarr` method to create a `Kerchunk` index from a NetCDF file.\n",
    "def generate_json_reference(u, output_dir: str):\n",
    "    with fs_read.open(u, **so_dict) as infile:\n",
    "        h5chunks = SingleHdf5ToZarr(infile, u, inline_threshold=300)\n",
    "        fname = u.split(\"/\")[-1].strip(\".nc\")\n",
    "        outf = f\"{output_dir}/{fname}.json\"\n",
    "        with open(outf, \"wb\") as f:\n",
    "            f.write(ujson.dumps(h5chunks.translate()).encode())\n",
    "        return outf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(file_pattern): generate_json_reference(file, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a32c5",
   "metadata": {},
   "source": [
    "## Combine the zarr jsons from above into a single combined one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd925589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerchunk.combine import MultiZarrToZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [f\"{output_dir}/{f.split('/')[-1].strip('.nc')}.json\" for f in file_pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = MultiZarrToZarr(json_files,\n",
    "                     remote_protocol='abfs',remote_options=account_dict,\n",
    "                     concat_dims=['time'], identical_dims=['nSCHISM_hgrid_node', 'nSCHISM_vgrid_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45dab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hindcast2_combined_1_1000.json','wb') as ofh: ofh.write(ujson.dumps(zz.translate()).encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3395e68",
   "metadata": {},
   "source": [
    "## Now use the combined json file to read the data\n",
    "\n",
    "** Note ** The previous steps can all be done once and the result cached in combined json. From then the lines below should be able to use it without problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a68135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_args = {\"consolidated\": False, \"storage_options\": {\"fo\": \"hindcast2_combined_1_1000.json\",\"remote_protocol\": \"abfs\",\"remote_options\": account_dict}}\n",
    "ds = xr.open_dataset(\"reference://\", engine=\"zarr\", backend_kwargs=backend_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b859356",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.salt.isel(nSCHISM_hgrid_node=1277, nSCHISM_vgrid_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aae293",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4446943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fe541c37d19bd001748e92c02715440003c24e68d2c970c945a21c7a9f32c2be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
